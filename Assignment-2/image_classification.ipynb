{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:04:59.201826Z",
     "start_time": "2024-10-13T11:04:59.195649Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "for dimension reduction look into LDA for class separability and SVD for sparse data\n",
    "SVD may be better for image data for its versatility and noise reduction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e067224aa1691da6"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "class ImageLoader(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, data_directory, image_size=(128, 128)):\n",
    "        self.data_directory = data_directory\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X=None, y=None):\n",
    "        images = []\n",
    "        labels = []\n",
    "        # get image labels from the folder names\n",
    "        class_labels = os.listdir(self.data_directory)\n",
    "        class_labels.sort()\n",
    "        # loop through directory\n",
    "        for label_idx, class_name in enumerate(class_labels):\n",
    "            class_dir = os.path.join(self.data_directory, class_name)\n",
    "            # wrong directory\n",
    "            if not os.path.isdir(class_dir): \n",
    "                continue\n",
    "            # loop through image files\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, file_name)\n",
    "                # check for valid image to load\n",
    "                if file_name.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    # load with opencv\n",
    "                    img = cv2.imread(file_path)\n",
    "                    # preprocessing\n",
    "                    # resize\n",
    "                    img_resized = cv2.resize(img, self.image_size)\n",
    "                    # grayscale\n",
    "                    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "                    # normalization\n",
    "                    img_gray_norm = img_gray / 255.0\n",
    "                    \n",
    "                    # append image with label\n",
    "                    images.append(img_gray_norm)\n",
    "                    labels.append(label_idx)\n",
    "                    \n",
    "        # convert to numpy\n",
    "        images = np.array(images)\n",
    "        labels = np.array(labels)\n",
    "        return images, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:24.557300Z",
     "start_time": "2024-10-13T11:09:24.552368Z"
    }
   },
   "id": "274f0b2090e00d17"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class SIFTFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=100):\n",
    "        # use opencv SIFT\n",
    "        self.sift = cv2.SIFT_create()\n",
    "        self.svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        sift_features = []\n",
    "        for img in X:\n",
    "            # uint8 images\n",
    "            img_uint8 = (img * 255).astype(np.uint8)\n",
    "            kp, des = self.sift.detectAndCompute(img_uint8, None)\n",
    "            sift_features.append(des.flatten() if des is not None else np.zeros(128))\n",
    "        sift_features = np.array([f for f in sift_features if f is not None])\n",
    "        # SVD dimension reduction\n",
    "        self.svd.fit(sift_features)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        sift_features = []\n",
    "        for img in X:\n",
    "            # SIFT takes in uint8 format images\n",
    "            img_uint8 = (img * 255).astype(np.uint8)\n",
    "            kp, des = self.sift.detectAndCompute(img_uint8, None)\n",
    "            # in case no features found\n",
    "            sift_features.append(des.flatten() if des is not None else np.zeros(128))\n",
    "        sift_features = np.array([f for f in sift_features if f is not None])\n",
    "        return np.array(sift_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:25.771749Z",
     "start_time": "2024-10-13T11:09:25.766358Z"
    }
   },
   "id": "b7b9a982ced01152"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "class FourierFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        fft_features = []\n",
    "        for img in X:\n",
    "            # fft\n",
    "            f_transform = np.fft.fft2(img)\n",
    "            # shift zero frequency to center\n",
    "            f_shift = np.fft.fftshift(f_transform)\n",
    "            magnitude_spectrum = 20 * np.log(np.abs(f_shift))\n",
    "            fft_features.append(magnitude_spectrum.flatten())\n",
    "        return np.array(fft_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:26.419269Z",
     "start_time": "2024-10-13T11:09:26.413159Z"
    }
   },
   "id": "1485633cfece9920"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# set variable\n",
    "data_directory = 'data/BigCats'\n",
    "RANDOM_SEED = 192\n",
    "# kNN neighbors\n",
    "number_neighbor = 5\n",
    "# SVD components\n",
    "n_components = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:26.888227Z",
     "start_time": "2024-10-13T11:09:26.884366Z"
    }
   },
   "id": "66b8add9eaec198c"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "naive_bayes = GaussianNB()\n",
    "knn = KNeighborsClassifier(n_neighbors=number_neighbor)\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:27.325811Z",
     "start_time": "2024-10-13T11:09:27.321604Z"
    }
   },
   "id": "5d5027eec53669ca"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# define the pipelines for different classification methods\n",
    "sift_decision_tree_pipeline = Pipeline([\n",
    "    ('sift', SIFTFeatureExtractor(n_components=n_components)),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=RANDOM_SEED))\n",
    "])\n",
    "sift_naive_bayes_pipeline = Pipeline([\n",
    "    ('sift', SIFTFeatureExtractor(n_components=n_components)),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "sift_knn_pipeline = Pipeline([\n",
    "    ('sift', SIFTFeatureExtractor(n_components=n_components)),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=number_neighbor))\n",
    "])\n",
    "fourier_decision_tree_pipeline = Pipeline([\n",
    "    ('fourier', FourierFeatureExtractor()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "fourier_naive_bayes_pipeline = Pipeline([\n",
    "    ('fourier', FourierFeatureExtractor()),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "fourier_knn_pipeline = Pipeline([\n",
    "    ('fourier', FourierFeatureExtractor()),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=number_neighbor))\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:27.788365Z",
     "start_time": "2024-10-13T11:09:27.784521Z"
    }
   },
   "id": "d2e07e6ccac01617"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# data load and split\n",
    "image_loader = ImageLoader(data_directory=data_directory, image_size=(128, 128))\n",
    "images, labels = image_loader.fit_transform(None)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=RANDOM_SEED)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:28.968747Z",
     "start_time": "2024-10-13T11:09:28.713452Z"
    }
   },
   "id": "73770780f4459a78"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 128, 128)\n",
      "(136,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:29.703938Z",
     "start_time": "2024-10-13T11:09:29.694866Z"
    }
   },
   "id": "cb30f09f9a849c81"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (136,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[70], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# example call so far\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# still need parameter search\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# maybe dimension reduction\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# or other things\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m sift_decision_tree_pipeline\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m      6\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m sift_decision_tree_pipeline\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSIFT + Decision Tree: Accuracy =\u001B[39m\u001B[38;5;124m\"\u001B[39m, accuracy_score(y_test, y_pred), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF1-Score =\u001B[39m\u001B[38;5;124m\"\u001B[39m, f1_score(y_test, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweighted\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:416\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model.\u001B[39;00m\n\u001B[1;32m    391\u001B[0m \n\u001B[1;32m    392\u001B[0m \u001B[38;5;124;03mFit all the transformers one after the other and transform the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;124;03m    Pipeline with fitted steps.\u001B[39;00m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    415\u001B[0m fit_params_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_fit_params(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m--> 416\u001B[0m Xt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_steps)\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:370\u001B[0m, in \u001B[0;36mPipeline._fit\u001B[0;34m(self, X, y, **fit_params_steps)\u001B[0m\n\u001B[1;32m    368\u001B[0m     cloned_transformer \u001B[38;5;241m=\u001B[39m clone(transformer)\n\u001B[1;32m    369\u001B[0m \u001B[38;5;66;03m# Fit or load from cache the current transformer\u001B[39;00m\n\u001B[0;32m--> 370\u001B[0m X, fitted_transformer \u001B[38;5;241m=\u001B[39m fit_transform_one_cached(\n\u001B[1;32m    371\u001B[0m     cloned_transformer,\n\u001B[1;32m    372\u001B[0m     X,\n\u001B[1;32m    373\u001B[0m     y,\n\u001B[1;32m    374\u001B[0m     \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    375\u001B[0m     message_clsname\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeline\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    376\u001B[0m     message\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log_message(step_idx),\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_steps[name],\n\u001B[1;32m    378\u001B[0m )\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# Replace the transformer of the step with the fitted\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# transformer. This is necessary when loading the transformer\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# from the cache.\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[step_idx] \u001B[38;5;241m=\u001B[39m (name, fitted_transformer)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/memory.py:349\u001B[0m, in \u001B[0;36mNotMemorizedFunc.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 349\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001B[0m, in \u001B[0;36m_fit_transform_one\u001B[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001B[0m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 950\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit_transform(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    951\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    952\u001B[0m         res \u001B[38;5;241m=\u001B[39m transformer\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    143\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    146\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:918\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    915\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    917\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m--> 918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "Cell \u001B[0;32mIn[63], line 14\u001B[0m, in \u001B[0;36mSIFTFeatureExtractor.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     12\u001B[0m     kp, des \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msift\u001B[38;5;241m.\u001B[39mdetectAndCompute(img_uint8, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m     sift_features\u001B[38;5;241m.\u001B[39mappend(des\u001B[38;5;241m.\u001B[39mflatten() \u001B[38;5;28;01mif\u001B[39;00m des \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m128\u001B[39m))\n\u001B[0;32m---> 14\u001B[0m sift_features \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([f \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m sift_features \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m])\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# SVD dimension reduction\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msvd\u001B[38;5;241m.\u001B[39mfit(sift_features)\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (136,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# example call so far\n",
    "# still need parameter search\n",
    "# maybe dimension reduction\n",
    "# or other things\n",
    "sift_decision_tree_pipeline.fit(X_train, y_train)\n",
    "y_pred = sift_decision_tree_pipeline.predict(X_test)\n",
    "print(\"SIFT + Decision Tree: Accuracy =\", accuracy_score(y_test, y_pred), \"F1-Score =\", f1_score(y_test, y_pred, average='weighted'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T11:09:31.267033Z",
     "start_time": "2024-10-13T11:09:30.833786Z"
    }
   },
   "id": "b624dd36c9881a29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "86263ae95ba2ddc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
